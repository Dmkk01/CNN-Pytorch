{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "yellow-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "destroyed-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hindu-jordan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "perfect-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "formed-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "human-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_channels (int):  Number of input channels.\n",
    "          out_channels (int): Number of output channels.\n",
    "          stride (int):       Controls the stride.\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.skip = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "        else:\n",
    "            self.skip = None\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.block(x)\n",
    "        if self.skip is not None:\n",
    "            out = out + self.skip(x)\n",
    "        else:\n",
    "            out = out + x\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "empty-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Block_shapes():\n",
    "\n",
    "    # The number of channels and resolution do not change\n",
    "    batch_size = 20\n",
    "    x = torch.zeros(batch_size, 16, 28, 28)\n",
    "    block = Block(in_channels=16, out_channels=16)\n",
    "    y = block(x)\n",
    "    assert y.shape == torch.Size([batch_size, 16, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    # Increase the number of channels\n",
    "    block = Block(in_channels=16, out_channels=32)\n",
    "    y = block(x)\n",
    "    assert y.shape == torch.Size([batch_size, 32, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    # Decrease the resolution\n",
    "    block = Block(in_channels=16, out_channels=16, stride=2)\n",
    "    y = block(x)\n",
    "    assert y.shape == torch.Size([batch_size, 16, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    # Increase the number of channels and decrease the resolution\n",
    "    block = Block(in_channels=16, out_channels=32, stride=2)\n",
    "    y = block(x)\n",
    "    assert y.shape == torch.Size([batch_size, 32, 14, 14]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_Block_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "tutorial-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group of blocks\n",
    "class GroupOfBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n",
    "        super(GroupOfBlocks, self).__init__()\n",
    "\n",
    "        first_block = Block(in_channels, out_channels, stride)\n",
    "        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n",
    "        self.group = nn.Sequential(first_block, *other_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.group(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "absent-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels=64, num_classes=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_blocks (list):   A list with three elements which contains the number of blocks in \n",
    "                             each of the three groups of blocks in ResNet.\n",
    "                             For instance, n_blocks = [2, 4, 6] means that the first group has two blocks,\n",
    "                             the second group has four blocks and the third one has six blocks.\n",
    "          n_channels (int):  Number of channels in the first group of blocks.\n",
    "          num_classes (int): Number of classes.\n",
    "        \"\"\"\n",
    "        assert len(n_blocks) == 3, \"The number of groups should be three.\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.group1 = GroupOfBlocks(n_channels, n_channels, n_blocks[0])\n",
    "        self.group2 = GroupOfBlocks(n_channels, 2*n_channels, n_blocks[1], stride=2)\n",
    "        self.group3 = GroupOfBlocks(2*n_channels, 4*n_channels, n_blocks[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "        self.fc = nn.Linear(4*n_channels, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        if verbose: print('conv1:  ', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        if verbose: print('bn1:    ', x.shape)\n",
    "        x = self.relu(x)\n",
    "        if verbose: print('relu:   ', x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        if verbose: print('maxpool:', x.shape)\n",
    "\n",
    "        x = self.group1(x)\n",
    "        if verbose: print('group1: ', x.shape)\n",
    "        x = self.group2(x)\n",
    "        if verbose: print('group2: ', x.shape)\n",
    "        x = self.group3(x)\n",
    "        if verbose: print('group3: ', x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        if verbose: print('avgpool:', x.shape)\n",
    "\n",
    "        x = x.view(-1, self.fc.in_features)\n",
    "        if verbose: print('x.view: ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        if verbose: print('out:    ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "controlling-price",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "conv1:   torch.Size([32, 10, 28, 28])\n",
      "bn1:     torch.Size([32, 10, 28, 28])\n",
      "relu:    torch.Size([32, 10, 28, 28])\n",
      "maxpool: torch.Size([32, 10, 14, 14])\n",
      "group1:  torch.Size([32, 10, 14, 14])\n",
      "group2:  torch.Size([32, 20, 7, 7])\n",
      "group3:  torch.Size([32, 40, 4, 4])\n",
      "avgpool: torch.Size([32, 40, 1, 1])\n",
      "x.view:  torch.Size([32, 40])\n",
      "out:     torch.Size([32, 10])\n",
      "torch.Size([32, 10])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_ResNet_shapes():\n",
    "    # Create a network with 2 block in each of the three groups\n",
    "    n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "    net = ResNet(n_blocks, n_channels=10)\n",
    "    net.to(device)\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = iter(trainloader).next()\n",
    "        images = images.to(device)\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net.forward(images, verbose=True)\n",
    "        print(y.shape)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_ResNet_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surrounded-nightmare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "french-denmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (group1): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group2): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group3): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (skip): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=16)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "amended-shark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "idx: 0, loss: 2.332498550415039\n",
      "idx: 100, loss: 0.7401666641235352\n",
      "idx: 200, loss: 0.3168022930622101\n",
      "idx: 300, loss: 0.6699246764183044\n",
      "idx: 400, loss: 0.3960414230823517\n",
      "idx: 500, loss: 0.38464730978012085\n",
      "idx: 600, loss: 0.2812509536743164\n",
      "idx: 700, loss: 0.3503393828868866\n",
      "idx: 800, loss: 0.32765451073646545\n",
      "idx: 900, loss: 0.4673905372619629\n",
      "idx: 1000, loss: 0.18668022751808167\n",
      "idx: 1100, loss: 0.27778181433677673\n",
      "idx: 1200, loss: 0.42161211371421814\n",
      "idx: 1300, loss: 0.44894370436668396\n",
      "idx: 1400, loss: 0.1765088438987732\n",
      "idx: 1500, loss: 0.34054359793663025\n",
      "idx: 1600, loss: 0.4407752752304077\n",
      "idx: 1700, loss: 0.2971867024898529\n",
      "idx: 1800, loss: 0.19874830543994904\n",
      "Epoch: 1\n",
      "idx: 0, loss: 0.3573720455169678\n",
      "idx: 100, loss: 0.29730889201164246\n",
      "idx: 200, loss: 0.3870174288749695\n",
      "idx: 300, loss: 0.18340453505516052\n",
      "idx: 400, loss: 0.4064258635044098\n",
      "idx: 500, loss: 0.5987681150436401\n",
      "idx: 600, loss: 0.3327520489692688\n",
      "idx: 700, loss: 0.3116636276245117\n",
      "idx: 800, loss: 0.1839645355939865\n",
      "idx: 900, loss: 0.6279993057250977\n",
      "idx: 1000, loss: 0.3997095823287964\n",
      "idx: 1100, loss: 0.3353523313999176\n",
      "idx: 1200, loss: 0.2694462835788727\n",
      "idx: 1300, loss: 0.22811265289783478\n",
      "idx: 1400, loss: 0.2548505663871765\n",
      "idx: 1500, loss: 0.27364736795425415\n",
      "idx: 1600, loss: 0.19991913437843323\n",
      "idx: 1700, loss: 0.20506876707077026\n",
      "idx: 1800, loss: 0.3060030937194824\n",
      "Epoch: 2\n",
      "idx: 0, loss: 0.30993470549583435\n",
      "idx: 100, loss: 0.3389507830142975\n",
      "idx: 200, loss: 0.3506430983543396\n",
      "idx: 300, loss: 0.40856069326400757\n",
      "idx: 400, loss: 0.21366353332996368\n",
      "idx: 500, loss: 0.11661270260810852\n",
      "idx: 600, loss: 0.27946919202804565\n",
      "idx: 700, loss: 0.11907273530960083\n",
      "idx: 800, loss: 0.24378935992717743\n",
      "idx: 900, loss: 0.3279435932636261\n",
      "idx: 1000, loss: 0.19754500687122345\n",
      "idx: 1100, loss: 0.40307700634002686\n",
      "idx: 1200, loss: 0.4597280025482178\n",
      "idx: 1300, loss: 0.23277057707309723\n",
      "idx: 1400, loss: 0.1987777054309845\n",
      "idx: 1500, loss: 0.17889748513698578\n",
      "idx: 1600, loss: 0.18165487051010132\n",
      "idx: 1700, loss: 0.31930699944496155\n",
      "idx: 1800, loss: 0.2922874391078949\n",
      "Epoch: 3\n",
      "idx: 0, loss: 0.1640605479478836\n",
      "idx: 100, loss: 0.20173944532871246\n",
      "idx: 200, loss: 0.2733302414417267\n",
      "idx: 300, loss: 0.41327765583992004\n",
      "idx: 400, loss: 0.05223243311047554\n",
      "idx: 500, loss: 0.5171341896057129\n",
      "idx: 600, loss: 0.2732052505016327\n",
      "idx: 700, loss: 0.16894711554050446\n",
      "idx: 800, loss: 0.21582137048244476\n",
      "idx: 900, loss: 0.2249956727027893\n",
      "idx: 1000, loss: 0.3192219138145447\n",
      "idx: 1100, loss: 0.13715408742427826\n",
      "idx: 1200, loss: 0.3015320301055908\n",
      "idx: 1300, loss: 0.45446693897247314\n",
      "idx: 1400, loss: 0.31160008907318115\n",
      "idx: 1500, loss: 0.16433008015155792\n",
      "idx: 1600, loss: 0.264578253030777\n",
      "idx: 1700, loss: 0.18686886131763458\n",
      "idx: 1800, loss: 0.15961246192455292\n",
      "Epoch: 4\n",
      "idx: 0, loss: 0.0948813408613205\n",
      "idx: 100, loss: 0.13456808030605316\n",
      "idx: 200, loss: 0.2883440852165222\n",
      "idx: 300, loss: 0.06307493895292282\n",
      "idx: 400, loss: 0.23607784509658813\n",
      "idx: 500, loss: 0.12334127724170685\n",
      "idx: 600, loss: 0.4854465126991272\n",
      "idx: 700, loss: 0.11644462496042252\n",
      "idx: 800, loss: 0.19302912056446075\n",
      "idx: 900, loss: 0.17352183163166046\n",
      "idx: 1000, loss: 0.1985839605331421\n",
      "idx: 1100, loss: 0.15904268622398376\n",
      "idx: 1200, loss: 0.0979941338300705\n",
      "idx: 1300, loss: 0.07346577942371368\n",
      "idx: 1400, loss: 0.11790904402732849\n",
      "idx: 1500, loss: 0.06256335228681564\n",
      "idx: 1600, loss: 0.49608513712882996\n",
      "idx: 1700, loss: 0.13098585605621338\n",
      "idx: 1800, loss: 0.14751885831356049\n",
      "Epoch: 5\n",
      "idx: 0, loss: 0.18593764305114746\n",
      "idx: 100, loss: 0.15929357707500458\n",
      "idx: 200, loss: 0.296874076128006\n",
      "idx: 300, loss: 0.22787365317344666\n",
      "idx: 400, loss: 0.14714142680168152\n",
      "idx: 500, loss: 0.1562502086162567\n",
      "idx: 600, loss: 0.24554720520973206\n",
      "idx: 700, loss: 0.2715833783149719\n",
      "idx: 800, loss: 0.05018274858593941\n",
      "idx: 900, loss: 0.3466656804084778\n",
      "idx: 1000, loss: 0.12622927129268646\n",
      "idx: 1100, loss: 0.1054091528058052\n",
      "idx: 1200, loss: 0.314808189868927\n",
      "idx: 1300, loss: 0.11334259808063507\n",
      "idx: 1400, loss: 0.17557485401630402\n",
      "idx: 1500, loss: 0.2086625099182129\n",
      "idx: 1600, loss: 0.3591907322406769\n",
      "idx: 1700, loss: 0.1565776765346527\n",
      "idx: 1800, loss: 0.2556680142879486\n",
      "Epoch: 6\n",
      "idx: 0, loss: 0.2794240117073059\n",
      "idx: 100, loss: 0.1917438954114914\n",
      "idx: 200, loss: 0.25219953060150146\n",
      "idx: 300, loss: 0.16733244061470032\n",
      "idx: 400, loss: 0.15619532763957977\n",
      "idx: 500, loss: 0.3320484161376953\n",
      "idx: 600, loss: 0.17832563817501068\n",
      "idx: 700, loss: 0.188705176115036\n",
      "idx: 800, loss: 0.10397347807884216\n",
      "idx: 900, loss: 0.31055396795272827\n",
      "idx: 1000, loss: 0.2461734265089035\n",
      "idx: 1100, loss: 0.10930196195840836\n",
      "idx: 1200, loss: 0.27505725622177124\n",
      "idx: 1300, loss: 0.09226839989423752\n",
      "idx: 1400, loss: 0.123277448117733\n",
      "idx: 1500, loss: 0.3349577486515045\n",
      "idx: 1600, loss: 0.3098355233669281\n",
      "idx: 1700, loss: 0.19619259238243103\n",
      "idx: 1800, loss: 0.3115112781524658\n",
      "Epoch: 7\n",
      "idx: 0, loss: 0.279630184173584\n",
      "idx: 100, loss: 0.08693180233240128\n",
      "idx: 200, loss: 0.08399592339992523\n",
      "idx: 300, loss: 0.1203681230545044\n",
      "idx: 400, loss: 0.1262577772140503\n",
      "idx: 500, loss: 0.04509112611413002\n",
      "idx: 600, loss: 0.16885501146316528\n",
      "idx: 700, loss: 0.035578858107328415\n",
      "idx: 800, loss: 0.13846556842327118\n",
      "idx: 900, loss: 0.14194084703922272\n",
      "idx: 1000, loss: 0.337444931268692\n",
      "idx: 1100, loss: 0.2041337788105011\n",
      "idx: 1200, loss: 0.15733470022678375\n",
      "idx: 1300, loss: 0.17570684850215912\n",
      "idx: 1400, loss: 0.18516770005226135\n",
      "idx: 1500, loss: 0.13595323264598846\n",
      "idx: 1600, loss: 0.10956928879022598\n",
      "idx: 1700, loss: 0.09421573579311371\n",
      "idx: 1800, loss: 0.25517329573631287\n",
      "Epoch: 8\n",
      "idx: 0, loss: 0.11000961810350418\n",
      "idx: 100, loss: 0.10437607020139694\n",
      "idx: 200, loss: 0.11253348737955093\n",
      "idx: 300, loss: 0.07860247045755386\n",
      "idx: 400, loss: 0.16387902200222015\n",
      "idx: 500, loss: 0.31688573956489563\n",
      "idx: 600, loss: 0.4325397312641144\n",
      "idx: 700, loss: 0.1532658189535141\n",
      "idx: 800, loss: 0.08338133245706558\n",
      "idx: 900, loss: 0.2912897765636444\n",
      "idx: 1000, loss: 0.13065628707408905\n",
      "idx: 1100, loss: 0.028345437720417976\n",
      "idx: 1200, loss: 0.18692660331726074\n",
      "idx: 1300, loss: 0.17387175559997559\n",
      "idx: 1400, loss: 0.2043914943933487\n",
      "idx: 1500, loss: 0.08442088961601257\n",
      "idx: 1600, loss: 0.187727689743042\n",
      "idx: 1700, loss: 0.2746052145957947\n",
      "idx: 1800, loss: 0.17992062866687775\n",
      "Epoch: 9\n",
      "idx: 0, loss: 0.05945916473865509\n",
      "idx: 100, loss: 0.2348785102367401\n",
      "idx: 200, loss: 0.11651743948459625\n",
      "idx: 300, loss: 0.056274496018886566\n",
      "idx: 400, loss: 0.034054554998874664\n",
      "idx: 500, loss: 0.04421138018369675\n",
      "idx: 600, loss: 0.04770897328853607\n",
      "idx: 700, loss: 0.02373633347451687\n",
      "idx: 800, loss: 0.3717327117919922\n",
      "idx: 900, loss: 0.07084488123655319\n",
      "idx: 1000, loss: 0.03184908255934715\n",
      "idx: 1100, loss: 0.030627477914094925\n",
      "idx: 1200, loss: 0.06254217028617859\n",
      "idx: 1300, loss: 0.15339447557926178\n",
      "idx: 1400, loss: 0.30366066098213196\n",
      "idx: 1500, loss: 0.022343967109918594\n",
      "idx: 1600, loss: 0.17509981989860535\n",
      "idx: 1700, loss: 0.21223433315753937\n",
      "idx: 1800, loss: 0.1093662828207016\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "if not skip_training:\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        for idx, (train_x, train_label) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            predict_y = net(train_x.float())\n",
    "            loss = criterion(predict_y, train_label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {}'.format(idx, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "informal-craft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 3_resnet.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '3_resnet.pth')\n",
    "else:\n",
    "    net = ResNet(n_blocks, n_channels=16)\n",
    "    tools.load_model(net, '3_resnet.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "heavy-guitar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 0.917\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the network on the test images: %.3f' % accuracy)\n",
    "n_blocks = sum(type(m) == Block for _, m in net.named_modules())\n",
    "assert n_blocks == 6, f\"Wrong number ({n_blocks}) of blocks used in the network.\"\n",
    "\n",
    "assert accuracy > 0.9, \"Poor accuracy ({:.3f})\".format(accuracy)\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-yahoo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
