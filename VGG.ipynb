{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessory-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quantitative-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "urban-missouri",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anonymous-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "african-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sound-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        # Layer 1\n",
    "        self.conv1  = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=3, padding=(1, 1))\n",
    "        self.batch1 = nn.BatchNorm2d(20)\n",
    "        self.relu1   = nn.ReLU()\n",
    "        \n",
    "        self.conv2  = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, padding=(1, 1))\n",
    "        self.batch2 = nn.BatchNorm2d(20)\n",
    "        self.relu2  = nn.ReLU()\n",
    "        \n",
    "        self.conv3  = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, padding=(1, 1))\n",
    "        self.batch3 = nn.BatchNorm2d(20)\n",
    "        self.relu3  = nn.ReLU()\n",
    "\n",
    "        self.pool3  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Layer 2\n",
    "        self.conv4  = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=(1, 1))\n",
    "        self.batch4 = nn.BatchNorm2d(40)\n",
    "        self.relu4  = nn.ReLU()\n",
    "        \n",
    "        self.conv5  = nn.Conv2d(in_channels=40, out_channels=40, kernel_size=3, padding=(1, 1))\n",
    "        self.batch5 = nn.BatchNorm2d(40)\n",
    "        self.relu5  = nn.ReLU()\n",
    "        \n",
    "        self.conv6  = nn.Conv2d(in_channels=40, out_channels=40, kernel_size=3, padding=(1, 1))\n",
    "        self.batch6 = nn.BatchNorm2d(40)\n",
    "        self.relu6  = nn.ReLU()\n",
    "\n",
    "        self.pool6  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Layer 3\n",
    "        self.conv7  = nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3)\n",
    "        self.batch7 = nn.BatchNorm2d(60)\n",
    "        self.relu7  = nn.ReLU()\n",
    "        \n",
    "        # Layer 4\n",
    "        self.conv8  = nn.Conv2d(in_channels=60, out_channels=40, kernel_size=1)\n",
    "        self.batch8 = nn.BatchNorm2d(40)\n",
    "        self.relu8  = nn.ReLU()\n",
    "        \n",
    "        # Layer 5\n",
    "        self.conv9  = nn.Conv2d(in_channels=40, out_channels=20, kernel_size=1)\n",
    "        self.batch9 = nn.BatchNorm2d(20)\n",
    "        self.relu9  = nn.ReLU()\n",
    "        \n",
    "        self.pool9  = nn.AvgPool2d(kernel_size=5)\n",
    "        \n",
    "        # Layer 6\n",
    "        self.fc10   = nn.Linear(in_features=20, out_features=10)\n",
    "        \n",
    "\n",
    "    def forward(self, x, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        # Layer 1\n",
    "        y = self.conv1(x)\n",
    "        y = self.batch1(y)\n",
    "        y = self.relu1(y)\n",
    "        \n",
    "        y = self.conv2(y)\n",
    "        y = self.batch2(y)\n",
    "        y = self.relu2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.batch3(y)\n",
    "        y = self.relu3(y)\n",
    "        \n",
    "        y = self.pool3(y)\n",
    "        \n",
    "        # Layer 2\n",
    "        y = self.conv4(y)\n",
    "        y = self.batch4(y)\n",
    "        y = self.relu4(y)\n",
    "        \n",
    "        y = self.conv5(y)\n",
    "        y = self.batch5(y)\n",
    "        y = self.relu5(y)\n",
    "        \n",
    "        y = self.conv6(y)\n",
    "        y = self.batch6(y)\n",
    "        y = self.relu6(y)\n",
    "        \n",
    "        y = self.pool6(y)\n",
    "        \n",
    "        # Layer 3\n",
    "        y = self.conv7(y)\n",
    "        y = self.batch7(y)\n",
    "        y = self.relu7(y)\n",
    "        \n",
    "        # Layer 4\n",
    "        y = self.conv8(y)\n",
    "        y = self.batch8(y)\n",
    "        y = self.relu8(y)\n",
    "        \n",
    "        # Layer 5\n",
    "        y = self.conv9(y)\n",
    "        y = self.batch9(y)\n",
    "        y = self.relu9(y)\n",
    "        \n",
    "        y = self.pool9(y)\n",
    "        y = y.squeeze(-1).squeeze(-1)\n",
    "\n",
    "        # Layer 6\n",
    "        y = self.fc10(y)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beginning-attraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_VGGNet_shapes():\n",
    "    net = VGGNet()\n",
    "    net.to(device)\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = iter(trainloader).next()\n",
    "        images = images.to(device)\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net(images, verbose=True)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), f\"Bad y.shape: {y.shape}\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_VGGNet_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earned-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convinced-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "idx: 0, loss: 2.3608996868133545\n",
      "idx: 100, loss: 0.5725903511047363\n",
      "idx: 200, loss: 0.8095713257789612\n",
      "idx: 300, loss: 0.4059826731681824\n",
      "idx: 400, loss: 0.4826407730579376\n",
      "idx: 500, loss: 0.4274907112121582\n",
      "idx: 600, loss: 0.47818905115127563\n",
      "idx: 700, loss: 0.40309813618659973\n",
      "idx: 800, loss: 0.4287862479686737\n",
      "idx: 900, loss: 0.19556410610675812\n",
      "idx: 1000, loss: 0.2674909830093384\n",
      "idx: 1100, loss: 0.2615368962287903\n",
      "idx: 1200, loss: 0.3028201162815094\n",
      "idx: 1300, loss: 0.8580081462860107\n",
      "idx: 1400, loss: 0.28564900159835815\n",
      "idx: 1500, loss: 0.3364502787590027\n",
      "idx: 1600, loss: 0.2108387053012848\n",
      "idx: 1700, loss: 0.14377668499946594\n",
      "idx: 1800, loss: 0.2606153190135956\n",
      "Epoch: 1\n",
      "idx: 0, loss: 0.376329243183136\n",
      "idx: 100, loss: 0.31173932552337646\n",
      "idx: 200, loss: 0.14687323570251465\n",
      "idx: 300, loss: 0.17319948971271515\n",
      "idx: 400, loss: 0.35542377829551697\n",
      "idx: 500, loss: 0.2077597975730896\n",
      "idx: 600, loss: 0.5888223052024841\n",
      "idx: 700, loss: 0.3369978666305542\n",
      "idx: 800, loss: 0.17242836952209473\n",
      "idx: 900, loss: 0.40617045760154724\n",
      "idx: 1000, loss: 0.23716706037521362\n",
      "idx: 1100, loss: 0.11422909796237946\n",
      "idx: 1200, loss: 0.20303888618946075\n",
      "idx: 1300, loss: 0.18830075860023499\n",
      "idx: 1400, loss: 0.2081235945224762\n",
      "idx: 1500, loss: 0.2761387825012207\n",
      "idx: 1600, loss: 0.17137134075164795\n",
      "idx: 1700, loss: 0.3625788688659668\n",
      "idx: 1800, loss: 0.282177209854126\n",
      "Epoch: 2\n",
      "idx: 0, loss: 0.11066153645515442\n",
      "idx: 100, loss: 0.1729571372270584\n",
      "idx: 200, loss: 0.3466019928455353\n",
      "idx: 300, loss: 0.4345809519290924\n",
      "idx: 400, loss: 0.26606014370918274\n",
      "idx: 500, loss: 0.18990080058574677\n",
      "idx: 600, loss: 0.3751560151576996\n",
      "idx: 700, loss: 0.36370936036109924\n",
      "idx: 800, loss: 0.4561539888381958\n",
      "idx: 900, loss: 0.30488499999046326\n",
      "idx: 1000, loss: 0.443600058555603\n",
      "idx: 1100, loss: 0.14104829728603363\n",
      "idx: 1200, loss: 0.3536149263381958\n",
      "idx: 1300, loss: 0.24875296652317047\n",
      "idx: 1400, loss: 0.5168449282646179\n",
      "idx: 1500, loss: 0.2987976670265198\n",
      "idx: 1600, loss: 0.11627272516489029\n",
      "idx: 1700, loss: 0.2504594326019287\n",
      "idx: 1800, loss: 0.4852343499660492\n",
      "Epoch: 3\n",
      "idx: 0, loss: 0.4347451627254486\n",
      "idx: 100, loss: 0.2989133894443512\n",
      "idx: 200, loss: 0.262119859457016\n",
      "idx: 300, loss: 0.09213028848171234\n",
      "idx: 400, loss: 0.07750729471445084\n",
      "idx: 500, loss: 0.41605040431022644\n",
      "idx: 600, loss: 0.2042587697505951\n",
      "idx: 700, loss: 0.295118510723114\n",
      "idx: 800, loss: 0.17704150080680847\n",
      "idx: 900, loss: 0.20732226967811584\n",
      "idx: 1000, loss: 0.42769312858581543\n",
      "idx: 1100, loss: 0.22135210037231445\n",
      "idx: 1200, loss: 0.21468757092952728\n",
      "idx: 1300, loss: 0.29992997646331787\n",
      "idx: 1400, loss: 0.33187025785446167\n",
      "idx: 1500, loss: 0.27950501441955566\n",
      "idx: 1600, loss: 0.1906633824110031\n",
      "idx: 1700, loss: 0.11204835772514343\n",
      "idx: 1800, loss: 0.06849858909845352\n",
      "Epoch: 4\n",
      "idx: 0, loss: 0.2617412209510803\n",
      "idx: 100, loss: 0.1897100806236267\n",
      "idx: 200, loss: 0.0761464461684227\n",
      "idx: 300, loss: 0.11960936337709427\n",
      "idx: 400, loss: 0.3772801160812378\n",
      "idx: 500, loss: 0.28705844283103943\n",
      "idx: 600, loss: 0.17416414618492126\n",
      "idx: 700, loss: 0.36756575107574463\n",
      "idx: 800, loss: 0.05864664912223816\n",
      "idx: 900, loss: 0.10390336066484451\n",
      "idx: 1000, loss: 0.21637654304504395\n",
      "idx: 1100, loss: 0.41046109795570374\n",
      "idx: 1200, loss: 0.03785840794444084\n",
      "idx: 1300, loss: 0.1874275654554367\n",
      "idx: 1400, loss: 0.2595100700855255\n",
      "idx: 1500, loss: 0.24324089288711548\n",
      "idx: 1600, loss: 0.2501799762248993\n",
      "idx: 1700, loss: 0.16013257205486298\n",
      "idx: 1800, loss: 0.2239815592765808\n",
      "Epoch: 5\n",
      "idx: 0, loss: 0.21876563131809235\n",
      "idx: 100, loss: 0.24084196984767914\n",
      "idx: 200, loss: 0.11774807423353195\n",
      "idx: 300, loss: 0.12949518859386444\n",
      "idx: 400, loss: 0.15956880152225494\n",
      "idx: 500, loss: 0.10977371037006378\n",
      "idx: 600, loss: 0.1504300832748413\n",
      "idx: 700, loss: 0.14330248534679413\n",
      "idx: 800, loss: 0.2902420461177826\n",
      "idx: 900, loss: 0.16395287215709686\n",
      "idx: 1000, loss: 0.2703368663787842\n",
      "idx: 1100, loss: 0.2272782176733017\n",
      "idx: 1200, loss: 0.0852305218577385\n",
      "idx: 1300, loss: 0.18191008269786835\n",
      "idx: 1400, loss: 0.3323862552642822\n",
      "idx: 1500, loss: 0.3639259338378906\n",
      "idx: 1600, loss: 0.14306315779685974\n",
      "idx: 1700, loss: 0.47338029742240906\n",
      "idx: 1800, loss: 0.053311992436647415\n",
      "Epoch: 6\n",
      "idx: 0, loss: 0.17785507440567017\n",
      "idx: 100, loss: 0.16053278744220734\n",
      "idx: 200, loss: 0.20979435741901398\n",
      "idx: 300, loss: 0.09903525561094284\n",
      "idx: 400, loss: 0.3514794409275055\n",
      "idx: 500, loss: 0.1763862520456314\n",
      "idx: 600, loss: 0.05716695636510849\n",
      "idx: 700, loss: 0.08134867250919342\n",
      "idx: 800, loss: 0.3457225561141968\n",
      "idx: 900, loss: 0.1864263415336609\n",
      "idx: 1000, loss: 0.11808187514543533\n",
      "idx: 1100, loss: 0.40496623516082764\n",
      "idx: 1200, loss: 0.03758960962295532\n",
      "idx: 1300, loss: 0.3333667516708374\n",
      "idx: 1400, loss: 0.23823097348213196\n",
      "idx: 1500, loss: 0.28757333755493164\n",
      "idx: 1600, loss: 0.06028590351343155\n",
      "idx: 1700, loss: 0.32798662781715393\n",
      "idx: 1800, loss: 0.29181140661239624\n",
      "Epoch: 7\n",
      "idx: 0, loss: 0.0811065286397934\n",
      "idx: 100, loss: 0.19738197326660156\n",
      "idx: 200, loss: 0.09147021174430847\n",
      "idx: 300, loss: 0.09463875740766525\n",
      "idx: 400, loss: 0.4269157648086548\n",
      "idx: 500, loss: 0.11622069776058197\n",
      "idx: 600, loss: 0.14566297829151154\n",
      "idx: 700, loss: 0.18342937529087067\n",
      "idx: 800, loss: 0.11862652003765106\n",
      "idx: 900, loss: 0.10738764703273773\n",
      "idx: 1000, loss: 0.194688081741333\n",
      "idx: 1100, loss: 0.07567239552736282\n",
      "idx: 1200, loss: 0.11450717598199844\n",
      "idx: 1300, loss: 0.3028683662414551\n",
      "idx: 1400, loss: 0.3049919605255127\n",
      "idx: 1500, loss: 0.04408564791083336\n",
      "idx: 1600, loss: 0.2406495213508606\n",
      "idx: 1700, loss: 0.25314611196517944\n",
      "idx: 1800, loss: 0.023951388895511627\n",
      "Epoch: 8\n",
      "idx: 0, loss: 0.11647523939609528\n",
      "idx: 100, loss: 0.14661826193332672\n",
      "idx: 200, loss: 0.2702157497406006\n",
      "idx: 300, loss: 0.19406351447105408\n",
      "idx: 400, loss: 0.2353922724723816\n",
      "idx: 500, loss: 0.18075114488601685\n",
      "idx: 600, loss: 0.3256540298461914\n",
      "idx: 700, loss: 0.2788725793361664\n",
      "idx: 800, loss: 0.28665149211883545\n",
      "idx: 900, loss: 0.2511986494064331\n",
      "idx: 1000, loss: 0.1768997311592102\n",
      "idx: 1100, loss: 0.1556447446346283\n",
      "idx: 1200, loss: 0.1313980668783188\n",
      "idx: 1300, loss: 0.18036900460720062\n",
      "idx: 1400, loss: 0.24981285631656647\n",
      "idx: 1500, loss: 0.031515032052993774\n",
      "idx: 1600, loss: 0.04419291764497757\n",
      "idx: 1700, loss: 0.19177092611789703\n",
      "idx: 1800, loss: 0.12388399988412857\n",
      "Epoch: 9\n",
      "idx: 0, loss: 0.23964013159275055\n",
      "idx: 100, loss: 0.3238586187362671\n",
      "idx: 200, loss: 0.01835394650697708\n",
      "idx: 300, loss: 0.2927020192146301\n",
      "idx: 400, loss: 0.41084739565849304\n",
      "idx: 500, loss: 0.14105649292469025\n",
      "idx: 600, loss: 0.14653104543685913\n",
      "idx: 700, loss: 0.10934387147426605\n",
      "idx: 800, loss: 0.11699225753545761\n",
      "idx: 900, loss: 0.11253427714109421\n",
      "idx: 1000, loss: 0.1141519770026207\n",
      "idx: 1100, loss: 0.12175101786851883\n",
      "idx: 1200, loss: 0.07670094817876816\n",
      "idx: 1300, loss: 0.09538187831640244\n",
      "idx: 1400, loss: 0.11098285764455795\n",
      "idx: 1500, loss: 0.19309104979038239\n",
      "idx: 1600, loss: 0.13323888182640076\n",
      "idx: 1700, loss: 0.07014138996601105\n",
      "idx: 1800, loss: 0.11802943050861359\n"
     ]
    }
   ],
   "source": [
    "net = VGGNet()\n",
    "# Training loop\n",
    "if not skip_training:\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epochs = 10\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch: {}'.format(epoch))\n",
    "        for idx, (train_x, train_label) in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            predict_y = net(train_x.float())\n",
    "            loss = criterion(predict_y, train_label.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            if idx % 100 == 0:\n",
    "                print('idx: {}, loss: {}'.format(idx, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "recreational-dependence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 2_vgg_net.pth.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '2_vgg_net.pth')\n",
    "else:\n",
    "    net = VGGNet()\n",
    "    tools.load_model(net, '2_vgg_net.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "embedded-punishment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the VGG net on the test images:  0.925\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print(f'Accuracy of the VGG net on the test images: {accuracy: .3f}')\n",
    "assert accuracy > 0.89, 'Poor accuracy'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-discipline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
